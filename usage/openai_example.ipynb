{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# RefLex LLM - OpenAI Integration Example\n",
                "\n",
                "This notebook demonstrates how to use RefLex LLM specifically with OpenAI endpoints, including configuration, fallback capabilities, and best practices.\n",
                "\n",
                "## Installation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "5b48b255",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Requirement already satisfied: reflex-llms in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (0.1.0)\n",
                        "Requirement already satisfied: docker in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from reflex-llms) (7.1.0)\n",
                        "Requirement already satisfied: pytest in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from reflex-llms) (8.3.5)\n",
                        "Requirement already satisfied: python-dotenv in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from reflex-llms) (1.1.0)\n",
                        "Requirement already satisfied: openai in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from reflex-llms) (1.82.0)\n",
                        "Requirement already satisfied: pydantic>=2.0.0 in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from reflex-llms) (2.11.5)\n",
                        "Requirement already satisfied: PyYAML in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from reflex-llms) (6.0.2)\n",
                        "Requirement already satisfied: setuptools in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from reflex-llms) (80.9.0)\n",
                        "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from pydantic>=2.0.0->reflex-llms) (0.7.0)\n",
                        "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from pydantic>=2.0.0->reflex-llms) (2.33.2)\n",
                        "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from pydantic>=2.0.0->reflex-llms) (4.13.2)\n",
                        "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from pydantic>=2.0.0->reflex-llms) (0.4.1)\n",
                        "Requirement already satisfied: pywin32>=304 in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from docker->reflex-llms) (310)\n",
                        "Requirement already satisfied: requests>=2.26.0 in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from docker->reflex-llms) (2.32.3)\n",
                        "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from docker->reflex-llms) (2.4.0)\n",
                        "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from openai->reflex-llms) (4.9.0)\n",
                        "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from openai->reflex-llms) (1.9.0)\n",
                        "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from openai->reflex-llms) (0.28.1)\n",
                        "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from openai->reflex-llms) (0.10.0)\n",
                        "Requirement already satisfied: sniffio in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from openai->reflex-llms) (1.3.1)\n",
                        "Requirement already satisfied: tqdm>4 in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from openai->reflex-llms) (4.67.1)\n",
                        "Requirement already satisfied: colorama in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from pytest->reflex-llms) (0.4.6)\n",
                        "Requirement already satisfied: iniconfig in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from pytest->reflex-llms) (2.1.0)\n",
                        "Requirement already satisfied: packaging in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from pytest->reflex-llms) (25.0)\n",
                        "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from pytest->reflex-llms) (1.6.0)\n",
                        "Requirement already satisfied: idna>=2.8 in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai->reflex-llms) (3.10)\n",
                        "Requirement already satisfied: certifi in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai->reflex-llms) (2025.4.26)\n",
                        "Requirement already satisfied: httpcore==1.* in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai->reflex-llms) (1.0.9)\n",
                        "Requirement already satisfied: h11>=0.16 in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->reflex-llms) (0.16.0)\n",
                        "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\acisse\\codeworkspace\\reflex-llm\\.venv\\lib\\site-packages (from requests>=2.26.0->docker->reflex-llms) (3.4.2)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
                        "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
                    ]
                }
            ],
            "source": [
                "!pip install reflex-llms"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Basic OpenAI Usage"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using cached reflex configuration\n",
                        "Response: OpenAI and Reflex are innovative tools for natural language understanding and generation. How can I assist you today? Are you working on a specific project or facing any challenges with the technology? I'm here to help you find answers or provide guidance.\n",
                        "Using provider: reflex\n"
                    ]
                }
            ],
            "source": [
                "from reflex_llms import (\n",
                "    get_openai_client, \n",
                "    get_selected_provider,\n",
                ")\n",
                "\n",
                "# Get client with OpenAI preference\n",
                "client = get_openai_client(\n",
                "    preference_order=[\"openai\", \"reflex\"],\n",
                "    openai_base_url=\"https://wrong.address.com/v1\",\n",
                ")\n",
                "\n",
                "# Use exactly like the OpenAI client\n",
                "response = client.chat.completions.create(\n",
                "    model=\"gpt-3.5-turbo\",\n",
                "    messages=[\n",
                "        {\"role\": \"user\", \"content\": \"Hello! I'm using OpenAI through RefLex.\"}\n",
                "    ],\n",
                "    max_tokens=100\n",
                ")\n",
                "\n",
                "print(f\"Response: {response.choices[0].message.content}\")\n",
                "print(f\"Using provider: {get_selected_provider()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "6f8569f7",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using cached reflex configuration\n"
                    ]
                }
            ],
            "source": [
                "client = get_openai_client(\n",
                "    preference_order=[\"openai\", \"reflex\"],\n",
                "    openai_base_url=\"https://wrong.address.com/v1\",\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "ea6b3c4c",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Response: CreateEmbeddingResponse(data=[Embedding(embedding=[0.0008691217, 0.027443694, -0.1357695, -0.006981929, 0.043804947, -0.066955015, 0.06408625, -0.007891853, 0.011743882, -0.03970715, 0.028807608, 0.06722247, 0.05095649, 0.01118963, -0.0049538044, -0.018620186, 0.06305547, -0.011259739, -0.021611279, 0.010976157, -0.0043819984, -0.041408855, -0.0062828725, 0.03632305, 0.15982847, 0.03036786, 0.0431361, 0.043358844, -0.08415229, -0.031661786, 0.06642479, -0.04764157, 0.013351845, 0.015142062, -0.029296294, 0.0067227646, -0.021725835, 0.0426883, -0.0365096, 0.03347313, 0.0087062735, 0.010531868, 0.021179292, 0.0046447953, 0.0796105, -0.032350607, -0.0017474409, 0.0009717375, 0.07587133, -0.025479928, 0.019269366, -0.017003775, -0.09584733, -0.027847186, 0.05083585, 0.0024121522, -0.015586027, 0.034156267, 0.02212853, -0.05065058, 0.033891913, 0.027409155, -0.022231242, 0.043184325, 0.045827392, 0.025870772, -0.003041088, 0.038481493, 0.035482824, -0.02303227, 0.0115332175, 0.017811924, 0.015720544, 0.0029490353, -0.00530714, -0.0047483006, -0.027199538, -0.054434016, -0.016378412, 0.0034274769, 0.021069283, -0.055993028, 0.061800364, -0.025485119, 0.055070713, -0.03366267, -0.0027883374, 0.012614797, -0.008984925, 0.08496965, 0.06590734, 0.002338291, 0.03331869, 0.012341534, -0.027453998, 0.0012138728, 0.009987458, 0.015677897, -0.028713642, 0.018268473, -0.07436708, -0.0040012873, 0.01829239, -0.06409234, 0.04361333, 0.008087044, -0.012910624, -0.016133709, -0.008929994, 0.026900694, -0.024455352, 0.02712868, -0.020691304, -0.04484755, 0.023802103, -0.018350074, 0.051636912, -0.019053815, 0.02875227, 0.06221429, -0.018108232, -0.030712431, 0.0360544, 0.013703929, 0.058352534, -0.00218191, -0.045281246, -0.019801296, 1.9025807e-05, -0.056365553, -0.046368975, -0.017957885, -0.06206363, -0.017801777, 0.047016755, 0.0501978, -0.070197664, -0.06804542, 0.052162733, -0.017973687, -0.0061570117, 0.0012818845, -0.03389041, -0.017371956, -0.008757722, -0.03163226, 0.042957377, 0.0055000163, 0.02298055, 0.003574598, 0.0005131885, 0.05077391, -0.08496051, 0.051249873, 0.03187228, -0.022359457, -0.026225813, -0.013439706, 0.047119416, -0.047385756, 0.036976594, 0.011234701, -0.036530014, 0.065566204, -0.032778222, -0.097604, 0.044065468, 0.044424452, 0.04599643, 0.04799795, -0.072281726, -0.014299305, -0.018154724, -0.0325595, -0.004850212, -0.04118843, 0.023443848, -0.013640544, 0.04112688, 0.00020999103, 0.039961107, -0.04042119, -0.00053015654, -0.018961757, -0.014319483, 0.012067724, 0.028471, 0.016801106, 0.0009630813, -0.054899156, 0.024983805, -0.019616487, -0.058474623, -0.04203855, -0.029775014, -0.013326401, -0.013994816, -0.010098891, 0.069267675, 0.032420997, -0.0413843, -0.011287198, -0.07005125, 0.02267092, -0.012057072, 0.024519116, 0.034189634, -0.005085881, 0.0039283046, 0.03564965, 0.05349504, -0.016811745, -0.045234725, -0.0074825333, 0.032344513, 0.020344388, 0.0046383534, -0.05093866, -0.0027432346, -0.02193481, 0.07503478, -0.019439273, -0.0073648784, -0.063245386, -0.020740407, -0.055836, -0.051393617, -0.0020137297, -0.02770147, 0.014091718, -0.016414968, -0.036343984, 0.02622843, 0.030606594, 0.041402046, 0.03515483, 0.0067362315, 0.04711997, -0.033185642, -0.046516616, -0.0070954757, -0.017133398, 0.03582211, 0.054954346, -0.08477724, 0.023947, -0.03056591, -0.0054687783, -0.041803118, 0.0155669, -0.07438209, 0.015134564, 0.018970286, 0.027763586, -0.010099705, 0.013427853, -0.005906457, -0.028583044, 0.042707317, 0.0010372795, 0.017451482, -0.02118717, 0.007093564, 0.0032396154, -0.019636823, 0.019329485, 0.015932024, 0.01562613, 0.038317893, -0.02942487, 0.038053494, 0.024527397, 0.008826623, 0.008577984, 0.031601664, 0.037930816, 0.0394893, -0.00033282122, -0.029440146, 0.03430152, -0.0618401, -0.021214701, -0.06289739, -0.0004157075, 0.028475264, -0.0028132407, 0.004867928, 0.037867304, -0.013911083, 0.0124140885, 0.04665698, 0.014300826, -0.015070167, 0.06784752, -0.06306314, 0.0064129224, -0.015465551, 0.015431103, 0.024899833, 0.0013049763, 0.03485503, -0.022291102, 0.045279007, -0.015652016, 0.0027678192, -0.07873017, 0.03900885, 0.023906946, 0.035085198, 0.059590217, -0.031000836, 0.025903994, -0.04204343, 0.029458279, -0.022970252, 0.010681454, -0.008320389, 0.017394619, 0.02547421, 0.0035824303, 0.017237522, -0.054789435, -0.014961216, -0.0481437, 0.012799253, -0.003582379, -0.022311423, 0.04237327, 0.023967173, -0.04276715, 0.044543233, 0.057845082, 0.020391917, -0.037359096, 0.0064915223, 0.015960047, 0.014756432, 0.004213432, 0.0100022685, 0.03653598, 0.031194633, -0.05471954, 0.031346545, -0.085089214, -0.026578655, -0.02994413, 0.006943059, 0.021260533, -0.008885355, -0.0098489355, -0.014902456, 0.047578525, 0.00833825, -0.018661214, 0.010924997, -0.016894624, 0.02630182, 0.013773607, -0.0057951403, -0.0027694602, 0.038298544, 0.010769584, -0.022734733, -0.0023710998, 0.006855353, 0.008998928, 0.045314837, -0.0062856134, 0.0046244594, 0.013176497, 0.00030564668, -0.049799126, 0.03130536, -0.009114372, 0.018264849, 0.0087954365, -0.08330126, -0.012883775, -0.034077622, 0.024748692, -0.0064860205, -0.010522549, 0.029312473, 0.0032203717, 0.05315905, 0.024160348, -0.0035160051, -0.03453897, -0.013056144, 0.026043402, -0.018105248, -0.041255053, -0.008950075, 0.031170534, 0.026050625, -0.036638115, 0.041588053, 0.03907078, -0.02492831, 0.025121365, -0.0728359, -0.04093643, 0.00083051564, -0.040794633, -0.008330735, -0.0009777324, 0.018627346, 0.033812575, 0.026473265, 0.051195726, 0.023584476, -0.016032683, -0.028133078, -0.07225538, 0.031468756, 0.036646876, 0.046580303, 0.0071474295, -0.05191511, -0.032741334, 0.049499333, 0.043738667, 0.040054575, -0.040168647, 0.0013875205, 0.03257621, 0.03079903, 0.060253557, 0.032743055, -0.069718376, 0.0019964725, 0.040466994, 0.0247519, -0.026241124, -0.024638278, -0.009011982, 0.016308382, -0.01084496, 0.04989578, 0.01051406, 0.03198907, -0.019909833, -0.0435014, -0.03377853, -0.040755216, 0.06850161, 0.10936016, -0.013032693, -0.039985348, -0.012991123, -0.012852041, -0.0025531664, 0.019472314, 0.020496972, 0.09633099, -0.014344829, -0.039335087, 0.0112745995, 0.023294985, -0.0030661875, 0.047084294, -0.015761264, -0.050518516, 0.018160855, 0.07538037, 0.0037926426, 0.033929516, -0.06819393, 0.08021423, 0.05039053, 0.03234653, 0.015344575, 0.026185991, -0.058686215, -0.046234835, 0.0028509484, 0.0020527474, -0.00434466, 0.02275734, 0.08995953, -0.027773261, -0.03070428, -0.044412326, -0.08242018, -0.010351163, 0.036906373, 0.034464277, 0.0080209775, -0.023716051, 0.0060290443, 0.027486756, 0.014364981, 0.032079875, 0.03255378, -0.0050535533, 0.016676692, 0.024361473, 0.030459123, -0.04882393, -0.054970272, -0.008296334, -0.00060574134, -0.034762613, 0.045952532, 0.029840035, -0.033295967, -0.0028095322, -0.053091664, -0.014798532, -0.0037056548, 0.02809018, -0.0020046767, -0.013079357, 0.023812497, 0.032871842, 0.020658884, 0.024121864, -0.011732472, -0.10388959, 0.013406471, -0.0055900114, -0.07012406, 0.043312803, 0.0076654693, -0.06155141, -0.013505787, 0.032247275, -0.010433067, 0.051847905, -0.023721006, -0.013293704, 0.019490441, -0.0702046, -0.039252322, -0.014629861, -0.0388165, -0.04227457, 0.04866092, 0.054282777, 0.029380213, 0.0017086528, 0.031069165, 0.026760146, -0.02668169, 0.00018845308, 0.017012576, -0.026312953, 0.0028157374, -0.02021448, -0.0013742968, 0.028760908, -0.07576324, -0.009708266, -0.027648346, 0.019861767, 0.0023151343, -0.036827642, -0.04398204, 0.0010081037, -0.0022286375, 0.050108112, 0.029768461, 0.037812293, -0.013759369, 0.04087145, -0.062442813, 0.00879763, 0.008058994, 0.01808424, -0.017750146, 0.007935177, -0.03711463, -0.0073757377, 0.035473537, -0.009147352, -0.0027319922, -0.018814221, 0.011039093, -0.05607985, -0.009232982, -0.006716516, -0.07439405, 0.064197786, 0.03185112, -0.007049001, -0.010172638, -0.02612173, -0.015418908, -0.00797105, -0.027606249, -0.03376595, -0.040478617, -0.0087864455, -0.040822927, -0.026184667, 0.041232977, -0.011548286, -0.03342659, -0.041556068, -0.008686589, -0.02369029, -0.0063342494, 0.050253335, -0.042472467, -0.055051465, 0.028858861, 0.008391093, 0.012816362, 0.003982193, -0.023441382, 0.024004245, 0.042193357, -0.0015055791, -0.01060826, -0.016254066, -0.040545158, 0.043109454, -0.032591708, 0.008344765, -0.030677658, -0.03445759, -0.056950517, 0.04853112, -0.023427762, 0.0718378, -0.015877832, -0.05523604, -0.009787408, -0.009667529, 0.07909317, -0.028896593, -0.0054780454, -0.07636514, -0.009809738, -0.044402275, -0.015369407, -0.0022996166, -0.0008300351, 0.036275946, 0.06444784, 0.03956425, 0.014777046, -0.03988179, 0.042898823, 0.04477166, -0.0011660252, -0.0035901845, 0.046832, 0.0030476656, 0.023775984, 0.1049988, 0.048271503, 0.059098776, -0.053594694, 0.003897928, 0.0327603, -0.0213939, -0.0470502, -0.035202496, -0.04213911, 0.007230228, -0.011033527, -0.046767555, -0.03190307, 0.016210904, 0.00926448, -0.011405511, 0.0149158565, -0.055537928, -0.016174933, 0.009496575, 0.016147338, 0.012651779, 0.018299228, 0.0005531809, 0.056178663, 0.045510445, 0.013455522, 0.005719015, 0.035480324, 0.002799126, -0.024391757, 0.03228773, 0.0018987613, -0.020563457, -0.0018889017, -0.002684464, -0.013001153, -0.042066377, -0.08416735, -0.0106417155, -0.0007816136, -0.034321975, -0.0041753366, 0.008883521, -0.0031031086, -0.043088023, 0.003269367, -0.05846505, 0.05254731, -0.007762453, 0.046616666, 0.01989665, 0.035388045, 0.021325003, 0.008150929, 0.0029149072, -0.005605772, 0.018540839, -0.011826237, -0.043370895, 0.049169574, -0.028280891, 0.03495632, 0.006780848, -0.0044602486, -0.024973152, -0.0015936197, -0.0043981047, 0.00030291243, 0.03861777, -0.021393122, -0.041732524, -0.012760614, -0.059460644, -0.033096015, 0.029539837, -0.028258836, -0.01816607, -0.0063371607, 0.043737087, -0.041178264, -0.05115185, 0.043855242, -0.0067605176, 0.0076303924, -0.009240431, -0.07288509, -0.05941804, 0.027279435, -0.044612855, 0.0321574, -0.035097323, -0.0037513222, 0.008794014, -0.016785068, -0.02817506, 0.015093009, 0.012635848, -0.0045483424, 0.035862263, 0.008179359, -0.02651098, -0.0077804304, 0.040928572, -0.018425524, -0.024298875, 0.04296642, 0.13691345, -0.0067699305, 0.008993018, -0.03123094, -0.033124413, 0.016011199, -0.069206625, -0.042556293, -0.03725126, 0.0032078093], index=0, object='embedding')], model='text-embedding-ada-002', object='list', usage=Usage(prompt_tokens=11, total_tokens=11))\n",
                        "Using provider: reflex\n"
                    ]
                }
            ],
            "source": [
                "import reflex_llms\n",
                "\n",
                "# Use exactly like the OpenAI client\n",
                "response = client.embeddings.create(\n",
                "    model=\"text-embedding-ada-002\",\n",
                "    input=\"Hello! I'm using OpenAI through RefLex.\"\n",
                ")\n",
                "\n",
                "print(f\"Response: {response}\")\n",
                "print(f\"Using provider: {reflex_llms.get_selected_provider()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "f781accf",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Hi there! It's nice to meet you. Are you getting help with a project or have a specific question about using the OpenAI model through Reflex? I'd be happy to try and assist you. What can I help you with today?"
                    ]
                }
            ],
            "source": [
                "stream = client.chat.completions.create(\n",
                "    model=\"gpt-3.5-turbo\",\n",
                "    messages=[{\"role\": \"user\", \"content\": \"Hello! I'm using OpenAI through RefLex.\"}],\n",
                "    max_tokens=200,\n",
                "    stream=True\n",
                ")\n",
                "\n",
                "full_response = \"\"\n",
                "for chunk in stream:\n",
                "    if chunk.choices[0].delta.content is not None:\n",
                "        content = chunk.choices[0].delta.content\n",
                "        print(content, end=\"\", flush=True)\n",
                "        full_response += content"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "0f4e112c",
            "metadata": {},
            "outputs": [
                {
                    "ename": "NotFoundError",
                    "evalue": "Error code: 404 - {'error': {'message': 'model \"o4-mini\" not found, try pulling it first', 'type': 'api_error', 'param': None, 'code': None}}",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m stream = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mo4-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHello! I\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mm using OpenAI through RefLex.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\acisse\\CodeWorkspace\\reflex-llm\\.venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:287\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    285\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\acisse\\CodeWorkspace\\reflex-llm\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:925\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    882\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    883\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    884\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    922\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    923\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    924\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\acisse\\CodeWorkspace\\reflex-llm\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1239\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1225\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1227\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1234\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1235\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1236\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1237\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1238\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1239\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\acisse\\CodeWorkspace\\reflex-llm\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1034\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m             err.response.read()\n\u001b[32m   1033\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
                        "\u001b[31mNotFoundError\u001b[39m: Error code: 404 - {'error': {'message': 'model \"o4-mini\" not found, try pulling it first', 'type': 'api_error', 'param': None, 'code': None}}"
                    ]
                }
            ],
            "source": [
                "stream = client.chat.completions.create(\n",
                "    model=\"o4-mini\",\n",
                "    messages=[{\"role\": \"user\", \"content\": \"Hello! I'm using OpenAI through RefLex.\"}],\n",
                "    max_tokens=200,\n",
                "    stream=True\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "5550e8ce",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Using cached reflex configuration\n"
                    ]
                }
            ],
            "source": [
                "from reflex_llms import (\n",
                "    get_reflex_server, \n",
                "    is_using_reflex,\n",
                ")\n",
                "\n",
                "client2 = get_openai_client()\n",
                "server = get_reflex_server()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cb9f92c1",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3c9e1790",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9e1b715e",
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3bcc4364",
            "metadata": {},
            "outputs": [],
            "source": [
                "if server:\n",
                "    print(f\"RefLex server available: {server.openai_compatible_url}\")\n",
                "    print(f\"Server healthy: {server.is_healthy}\")\n",
                "else:\n",
                "    print(\"Not using RefLex server\")\n",
                "\n",
                "print(f\"\\nSelected provider: {get_selected_provider()}\")\n",
                "print(f\"Using RefLex: {is_using_reflex()}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
